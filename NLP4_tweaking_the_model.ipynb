{"cells":[{"cell_type":"markdown","metadata":{"id":"punL79CN7Ox6"},"source":["##### Copyright 2020 The TensorFlow Authors."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"_ckMIh7O7s6D"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"QrxSyyyhygUR"},"source":["# Tweaking the Model"]},{"cell_type":"markdown","metadata":{"id":"S5Uhzt6vVIB2"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l09c05_nlp_tweaking_the_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l09c05_nlp_tweaking_the_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"xiWacy71Cu54"},"source":["In this colab, you'll investigate how various tweaks to data processing and the model itself can impact results. At the end, you'll once again be able to visualize how the network sees the related sentiment of each word in the dataset."]},{"cell_type":"markdown","metadata":{"id":"hY-fjvwfy2P9"},"source":["## Import TensorFlow and related functions"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"drsUfVVXyxJl","executionInfo":{"status":"ok","timestamp":1709736467083,"user_tz":-60,"elapsed":4592,"user":{"displayName":"Quentin DAO CASTELLANA","userId":"11615130342282408666"}}},"outputs":[],"source":["import tensorflow as tf\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"markdown","metadata":{"id":"ZIf1N46jy6Ed"},"source":["## Get the dataset\n","\n","We'll once again use the dataset containing Amazon and Yelp reviews. This dataset was originally extracted from [here](https://www.kaggle.com/marklvl/sentiment-labelled-sentences-data-set)."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"m83g42sJzGO0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709736471658,"user_tz":-60,"elapsed":2409,"user":{"displayName":"Quentin DAO CASTELLANA","userId":"11615130342282408666"}},"outputId":"94511cc2-169e-45f0-b43d-265e691c7ab7"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-06 14:47:49--  https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\n","Resolving drive.google.com (drive.google.com)... 64.233.188.139, 64.233.188.113, 64.233.188.100, ...\n","Connecting to drive.google.com (drive.google.com)|64.233.188.139|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P [following]\n","--2024-03-06 14:47:50--  https://drive.usercontent.google.com/download?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 64.233.188.132, 2404:6800:4008:c06::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|64.233.188.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 127831 (125K) [application/octet-stream]\n","Saving to: ‘/tmp/sentiment.csv’\n","\n","/tmp/sentiment.csv  100%[===================>] 124.83K  --.-KB/s    in 0.003s  \n","\n","2024-03-06 14:47:51 (41.7 MB/s) - ‘/tmp/sentiment.csv’ saved [127831/127831]\n","\n"]}],"source":["!wget --no-check-certificate \\\n","    https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P \\\n","    -O /tmp/sentiment.csv"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"y4e6GG2CzJUq","executionInfo":{"status":"ok","timestamp":1709736474471,"user_tz":-60,"elapsed":4,"user":{"displayName":"Quentin DAO CASTELLANA","userId":"11615130342282408666"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","dataset = pd.read_csv('/tmp/sentiment.csv')\n","\n","sentences = dataset['text'].tolist()\n","labels = dataset['sentiment'].tolist()\n","\n","# Separate out the sentences and labels into training and test sets\n","training_size = int(len(sentences) * 0.8)\n","\n","training_sentences = sentences[0:training_size]\n","testing_sentences = sentences[training_size:]\n","training_labels = labels[0:training_size]\n","testing_labels = labels[training_size:]\n","\n","# Make labels into numpy arrays for use with the network later\n","training_labels_final = np.array(training_labels)\n","testing_labels_final = np.array(testing_labels)"]},{"cell_type":"markdown","metadata":{"id":"drDkTFMuzW6N"},"source":["## Tokenize the dataset (with tweaks!)\n","\n","Now, we'll tokenize the dataset, but we can make some changes to this from before. Previously, we used:\n","```\n","vocab_size = 1000\n","embedding_dim = 16\n","max_length = 100\n","trunc_type='post'\n","padding_type='post'\n","```\n","\n","How might changing the `vocab_size`, `embedding_dim` or `max_length` affect how the model performs?"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"hjPUJFhQzuee","executionInfo":{"status":"ok","timestamp":1709736482240,"user_tz":-60,"elapsed":531,"user":{"displayName":"Quentin DAO CASTELLANA","userId":"11615130342282408666"}}},"outputs":[],"source":["vocab_size = 500\n","embedding_dim = 16\n","max_length = 50\n","trunc_type='post'\n","padding_type='post'\n","oov_tok = \"<OOV>\"\n","\n","tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n","tokenizer.fit_on_texts(training_sentences)\n","word_index = tokenizer.word_index\n","training_sequences = tokenizer.texts_to_sequences(training_sentences)\n","training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n","testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"]},{"cell_type":"markdown","metadata":{"id":"FwFjO1kg0UUK"},"source":["## Train a Sentiment Model (with tweaks!)\n","\n","We'll use a slightly different model here, using `GlobalAveragePooling1D` instead of `Flatten()`."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ectP92fl0dFO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709736505201,"user_tz":-60,"elapsed":1762,"user":{"displayName":"Quentin DAO CASTELLANA","userId":"11615130342282408666"}},"outputId":"bc7b9d72-c1b2-4909-e03d-69fce1240d93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 50, 16)            8000      \n","                                                                 \n"," global_average_pooling1d (  (None, 16)                0         \n"," GlobalAveragePooling1D)                                         \n","                                                                 \n"," dense (Dense)               (None, 6)                 102       \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 7         \n","                                                                 \n","=================================================================\n","Total params: 8109 (31.68 KB)\n","Trainable params: 8109 (31.68 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    tf.keras.layers.GlobalAveragePooling1D(),\n","    tf.keras.layers.Dense(6, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"7TQIaGjs073w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709736550459,"user_tz":-60,"elapsed":42101,"user":{"displayName":"Quentin DAO CASTELLANA","userId":"11615130342282408666"}},"outputId":"e56b9c02-6f22-451c-cb58-3c9ff4394981"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","50/50 [==============================] - 8s 108ms/step - loss: 0.6926 - accuracy: 0.5543 - val_loss: 0.6931 - val_accuracy: 0.4862\n","Epoch 2/30\n","50/50 [==============================] - 2s 37ms/step - loss: 0.6907 - accuracy: 0.5587 - val_loss: 0.6924 - val_accuracy: 0.4912\n","Epoch 3/30\n","50/50 [==============================] - 2s 31ms/step - loss: 0.6879 - accuracy: 0.5945 - val_loss: 0.6912 - val_accuracy: 0.4937\n","Epoch 4/30\n","50/50 [==============================] - 0s 7ms/step - loss: 0.6838 - accuracy: 0.6246 - val_loss: 0.6859 - val_accuracy: 0.5689\n","Epoch 5/30\n","50/50 [==============================] - 1s 15ms/step - loss: 0.6770 - accuracy: 0.6780 - val_loss: 0.6787 - val_accuracy: 0.6291\n","Epoch 6/30\n","50/50 [==============================] - 1s 28ms/step - loss: 0.6672 - accuracy: 0.7288 - val_loss: 0.6680 - val_accuracy: 0.6942\n","Epoch 7/30\n","50/50 [==============================] - 1s 17ms/step - loss: 0.6534 - accuracy: 0.7502 - val_loss: 0.6665 - val_accuracy: 0.5865\n","Epoch 8/30\n","50/50 [==============================] - 0s 9ms/step - loss: 0.6345 - accuracy: 0.7677 - val_loss: 0.6450 - val_accuracy: 0.6867\n","Epoch 9/30\n","50/50 [==============================] - 1s 14ms/step - loss: 0.6113 - accuracy: 0.8010 - val_loss: 0.6200 - val_accuracy: 0.7694\n","Epoch 10/30\n","50/50 [==============================] - 0s 6ms/step - loss: 0.5863 - accuracy: 0.8136 - val_loss: 0.6134 - val_accuracy: 0.7118\n","Epoch 11/30\n","50/50 [==============================] - 1s 15ms/step - loss: 0.5583 - accuracy: 0.8205 - val_loss: 0.5883 - val_accuracy: 0.7619\n","Epoch 12/30\n","50/50 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.8324 - val_loss: 0.5682 - val_accuracy: 0.7619\n","Epoch 13/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.8424 - val_loss: 0.5607 - val_accuracy: 0.7494\n","Epoch 14/30\n","50/50 [==============================] - 0s 9ms/step - loss: 0.4736 - accuracy: 0.8525 - val_loss: 0.5347 - val_accuracy: 0.7845\n","Epoch 15/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.8537 - val_loss: 0.5399 - val_accuracy: 0.7444\n","Epoch 16/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.8531 - val_loss: 0.5136 - val_accuracy: 0.7769\n","Epoch 17/30\n","50/50 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8606 - val_loss: 0.5041 - val_accuracy: 0.7845\n","Epoch 18/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8694 - val_loss: 0.5025 - val_accuracy: 0.7644\n","Epoch 19/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8738 - val_loss: 0.5034 - val_accuracy: 0.7544\n","Epoch 20/30\n","50/50 [==============================] - 0s 8ms/step - loss: 0.3505 - accuracy: 0.8719 - val_loss: 0.4922 - val_accuracy: 0.7769\n","Epoch 21/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8807 - val_loss: 0.4903 - val_accuracy: 0.7744\n","Epoch 22/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.3233 - accuracy: 0.8832 - val_loss: 0.4914 - val_accuracy: 0.7669\n","Epoch 23/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.8864 - val_loss: 0.4850 - val_accuracy: 0.7694\n","Epoch 24/30\n","50/50 [==============================] - 0s 8ms/step - loss: 0.3029 - accuracy: 0.8939 - val_loss: 0.4807 - val_accuracy: 0.7744\n","Epoch 25/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8883 - val_loss: 0.4925 - val_accuracy: 0.7419\n","Epoch 26/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.2836 - accuracy: 0.8939 - val_loss: 0.4932 - val_accuracy: 0.7393\n","Epoch 27/30\n","50/50 [==============================] - 0s 5ms/step - loss: 0.2779 - accuracy: 0.8964 - val_loss: 0.4793 - val_accuracy: 0.7719\n","Epoch 28/30\n","50/50 [==============================] - 0s 6ms/step - loss: 0.2677 - accuracy: 0.9027 - val_loss: 0.4862 - val_accuracy: 0.7694\n","Epoch 29/30\n","50/50 [==============================] - 0s 10ms/step - loss: 0.2626 - accuracy: 0.9021 - val_loss: 0.4870 - val_accuracy: 0.7694\n","Epoch 30/30\n","50/50 [==============================] - 0s 7ms/step - loss: 0.2558 - accuracy: 0.9040 - val_loss: 0.4980 - val_accuracy: 0.7494\n"]}],"source":["num_epochs = 30\n","history = model.fit(training_padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"]},{"cell_type":"markdown","metadata":{"id":"alAlYort7gWV"},"source":["## Visualize the training graph\n","\n","You can use the code below to visualize the training and validation accuracy while you try out different tweaks to the hyperparameters and model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9l5vBeU71vH"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.show()\n","\n","plot_graphs(history, \"accuracy\")\n","plot_graphs(history, \"loss\")"]},{"cell_type":"markdown","metadata":{"id":"SZzXE-pT8K57"},"source":["## Get files for visualizing the network\n","\n","The code below will download two files for visualizing how your network \"sees\" the sentiment related to each word. Head to http://projector.tensorflow.org/ and load these files, then click the checkbox to \"sphereize\" the data.\n","\n","Note: You may run into errors with the projection if your `vocab_size` earlier was larger than the actual number of words in the vocabulary, in which case you'll need to decrease this variable and re-train in order to visualize."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Ex4o7Lc8Njl"},"outputs":[],"source":["# First get the weights of the embedding layer\n","e = model.layers[0]\n","weights = e.get_weights()[0]\n","print(weights.shape) # shape: (vocab_size, embedding_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUL1zk5p8WIV"},"outputs":[],"source":["import io\n","\n","# Create the reverse word index\n","reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","\n","# Write out the embedding vectors and metadata\n","out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n","out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n","for word_num in range(1, vocab_size):\n","  word = reverse_word_index[word_num]\n","  embeddings = weights[word_num]\n","  out_m.write(word + \"\\n\")\n","  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n","out_v.close()\n","out_m.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqyV8QYnD46U"},"outputs":[],"source":["# Download the files\n","try:\n","  from google.colab import files\n","except ImportError:\n","  pass\n","else:\n","  files.download('vecs.tsv')\n","  files.download('meta.tsv')"]},{"cell_type":"markdown","metadata":{"id":"XUXAlNNk59gG"},"source":["## Predicting Sentiment in New Reviews\n","\n","Below, we've again included some example new reviews you can test your results on."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbFTTcaK6Dan"},"outputs":[],"source":["# Use the model to predict a review\n","fake_reviews = ['I love this phone', 'I hate spaghetti',\n","                'Everything was cold',\n","                'Everything was hot exactly as I wanted',\n","                'Everything was green',\n","                'the host seated us immediately',\n","                'they gave us free chocolate cake',\n","                'not sure about the wilted flowers on the table',\n","                'only works when I stand on tippy toes',\n","                'does not work when I stand on my head']\n","\n","print(fake_reviews)\n","\n","# Create the sequences\n","padding_type='post'\n","sample_sequences = tokenizer.texts_to_sequences(fake_reviews)\n","fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)\n","\n","print('\\nHOT OFF THE PRESS! HERE ARE SOME NEWLY MINTED, ABSOLUTELY GENUINE REVIEWS!\\n')\n","\n","classes = model.predict(fakes_padded)\n","\n","# The closer the class is to 1, the more positive the review is deemed to be\n","for x in range(len(fake_reviews)):\n","  print(fake_reviews[x])\n","  print(classes[x])\n","  print('\\n')\n","\n","# Try adding reviews of your own\n","# Add some negative words (such as \"not\") to the good reviews and see what happens\n","# For example:\n","# they gave us free chocolate cake and did not charge us"]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[{"file_id":"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l09c05_nlp_tweaking_the_model.ipynb","timestamp":1709736199825}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}